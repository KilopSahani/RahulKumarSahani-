{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP6nhOMgxW6a8az2jgdmny9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KilopSahani/RahulKumarSahani-/blob/main/LLM_WebToGraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/LLM-WebToGraph/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_WnOr1ecoS6",
        "outputId": "a379ca3c-3cef-4be9-a434-a34e9ec93fbd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai (from -r /content/LLM-WebToGraph/requirements.txt (line 1))\n",
            "  Downloading openai-1.16.1-py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.9/266.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain (from -r /content/LLM-WebToGraph/requirements.txt (line 2))\n",
            "  Downloading langchain-0.1.14-py3-none-any.whl (812 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.8/812.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting playwright (from -r /content/LLM-WebToGraph/requirements.txt (line 3))\n",
            "  Downloading playwright-1.42.0-py3-none-manylinux1_x86_64.whl (37.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from -r /content/LLM-WebToGraph/requirements.txt (line 4)) (4.12.3)\n",
            "Collecting streamlit (from -r /content/LLM-WebToGraph/requirements.txt (line 5))\n",
            "  Downloading streamlit-1.32.2-py2.py3-none-any.whl (8.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from -r /content/LLM-WebToGraph/requirements.txt (line 6)) (1.0.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from -r /content/LLM-WebToGraph/requirements.txt (line 7)) (0.20.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r /content/LLM-WebToGraph/requirements.txt (line 8)) (4.38.2)\n",
            "Collecting neo4j (from -r /content/LLM-WebToGraph/requirements.txt (line 9))\n",
            "  Downloading neo4j-5.19.0.tar.gz (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.0/203.0 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bitsandbytes (from -r /content/LLM-WebToGraph/requirements.txt (line 10))\n",
            "  Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl (102.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate (from -r /content/LLM-WebToGraph/requirements.txt (line 11))\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from -r /content/LLM-WebToGraph/requirements.txt (line 12)) (2023.12.25)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from -r /content/LLM-WebToGraph/requirements.txt (line 13)) (0.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r /content/LLM-WebToGraph/requirements.txt (line 14)) (2.31.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from -r /content/LLM-WebToGraph/requirements.txt (line 15)) (0.29.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from -r /content/LLM-WebToGraph/requirements.txt (line 16)) (0.110.1)\n",
            "Collecting backoff (from -r /content/LLM-WebToGraph/requirements.txt (line 17))\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from -r /content/LLM-WebToGraph/requirements.txt (line 18)) (8.2.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r /content/LLM-WebToGraph/requirements.txt (line 19)) (2.2.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r /content/LLM-WebToGraph/requirements.txt (line 20)) (6.0.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from -r /content/LLM-WebToGraph/requirements.txt (line 21)) (3.7.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r /content/LLM-WebToGraph/requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai->-r /content/LLM-WebToGraph/requirements.txt (line 1)) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai->-r /content/LLM-WebToGraph/requirements.txt (line 1))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r /content/LLM-WebToGraph/requirements.txt (line 1)) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai->-r /content/LLM-WebToGraph/requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai->-r /content/LLM-WebToGraph/requirements.txt (line 1)) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai->-r /content/LLM-WebToGraph/requirements.txt (line 1)) (4.10.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/LLM-WebToGraph/requirements.txt (line 2)) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/LLM-WebToGraph/requirements.txt (line 2)) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/LLM-WebToGraph/requirements.txt (line 2)) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain->-r /content/LLM-WebToGraph/requirements.txt (line 2))\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain->-r /content/LLM-WebToGraph/requirements.txt (line 2))\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.30 (from langchain->-r /content/LLM-WebToGraph/requirements.txt (line 2))\n",
            "  Downloading langchain_community-0.0.31-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.37 (from langchain->-r /content/LLM-WebToGraph/requirements.txt (line 2))\n",
            "  Downloading langchain_core-0.1.38-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.2/279.2 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain->-r /content/LLM-WebToGraph/requirements.txt (line 2))\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain->-r /content/LLM-WebToGraph/requirements.txt (line 2))\n",
            "  Downloading langsmith-0.1.38-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/LLM-WebToGraph/requirements.txt (line 2)) (1.25.2)\n",
            "Requirement already satisfied: greenlet==3.0.3 in /usr/local/lib/python3.10/dist-packages (from playwright->-r /content/LLM-WebToGraph/requirements.txt (line 3)) (3.0.3)\n",
            "Collecting pyee==11.0.1 (from playwright->-r /content/LLM-WebToGraph/requirements.txt (line 3))\n",
            "  Downloading pyee-11.0.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->-r /content/LLM-WebToGraph/requirements.txt (line 4)) (2.5)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5)) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5)) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5)) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5)) (8.1.7)\n",
            "Collecting packaging<24,>=16.8 (from streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5))\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5)) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5)) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5)) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5)) (14.0.2)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5)) (13.7.1)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5)) (0.10.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5))\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5)) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5))\n",
            "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r /content/LLM-WebToGraph/requirements.txt (line 7)) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r /content/LLM-WebToGraph/requirements.txt (line 7)) (2023.6.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/LLM-WebToGraph/requirements.txt (line 8)) (0.15.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from neo4j->-r /content/LLM-WebToGraph/requirements.txt (line 9)) (2023.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r /content/LLM-WebToGraph/requirements.txt (line 11)) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/LLM-WebToGraph/requirements.txt (line 14)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/LLM-WebToGraph/requirements.txt (line 14)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/LLM-WebToGraph/requirements.txt (line 14)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/LLM-WebToGraph/requirements.txt (line 14)) (2024.2.2)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn->-r /content/LLM-WebToGraph/requirements.txt (line 15)) (0.14.0)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->-r /content/LLM-WebToGraph/requirements.txt (line 16)) (0.37.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/LLM-WebToGraph/requirements.txt (line 19)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/LLM-WebToGraph/requirements.txt (line 19)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/LLM-WebToGraph/requirements.txt (line 19)) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->-r /content/LLM-WebToGraph/requirements.txt (line 19))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->-r /content/LLM-WebToGraph/requirements.txt (line 19))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->-r /content/LLM-WebToGraph/requirements.txt (line 19))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->-r /content/LLM-WebToGraph/requirements.txt (line 19))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->-r /content/LLM-WebToGraph/requirements.txt (line 19))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->-r /content/LLM-WebToGraph/requirements.txt (line 19))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->-r /content/LLM-WebToGraph/requirements.txt (line 19))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->-r /content/LLM-WebToGraph/requirements.txt (line 19))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->-r /content/LLM-WebToGraph/requirements.txt (line 19))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch->-r /content/LLM-WebToGraph/requirements.txt (line 19))\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->-r /content/LLM-WebToGraph/requirements.txt (line 19))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/LLM-WebToGraph/requirements.txt (line 19)) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->-r /content/LLM-WebToGraph/requirements.txt (line 19))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/LLM-WebToGraph/requirements.txt (line 21)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/LLM-WebToGraph/requirements.txt (line 21)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/LLM-WebToGraph/requirements.txt (line 21)) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/LLM-WebToGraph/requirements.txt (line 21)) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/LLM-WebToGraph/requirements.txt (line 21)) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/LLM-WebToGraph/requirements.txt (line 21)) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/LLM-WebToGraph/requirements.txt (line 21)) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/LLM-WebToGraph/requirements.txt (line 21)) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/LLM-WebToGraph/requirements.txt (line 21)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/LLM-WebToGraph/requirements.txt (line 21)) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/LLM-WebToGraph/requirements.txt (line 21)) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/LLM-WebToGraph/requirements.txt (line 21)) (6.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/LLM-WebToGraph/requirements.txt (line 21)) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/LLM-WebToGraph/requirements.txt (line 21)) (3.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/LLM-WebToGraph/requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/LLM-WebToGraph/requirements.txt (line 2)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/LLM-WebToGraph/requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/LLM-WebToGraph/requirements.txt (line 2)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/LLM-WebToGraph/requirements.txt (line 2)) (1.9.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5)) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->-r /content/LLM-WebToGraph/requirements.txt (line 1)) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain->-r /content/LLM-WebToGraph/requirements.txt (line 2))\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain->-r /content/LLM-WebToGraph/requirements.txt (line 2))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore==1.* (from httpx<1,>=0.23.0->openai->-r /content/LLM-WebToGraph/requirements.txt (line 1))\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain->-r /content/LLM-WebToGraph/requirements.txt (line 2))\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain->-r /content/LLM-WebToGraph/requirements.txt (line 2))\n",
            "  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai->-r /content/LLM-WebToGraph/requirements.txt (line 1)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai->-r /content/LLM-WebToGraph/requirements.txt (line 1)) (2.16.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r /content/LLM-WebToGraph/requirements.txt (line 19)) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5)) (2.16.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->-r /content/LLM-WebToGraph/requirements.txt (line 21)) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->-r /content/LLM-WebToGraph/requirements.txt (line 21)) (0.1.4)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy->-r /content/LLM-WebToGraph/requirements.txt (line 21)) (0.16.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r /content/LLM-WebToGraph/requirements.txt (line 19)) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5)) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5)) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5)) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<3,>=1.3.0->streamlit->-r /content/LLM-WebToGraph/requirements.txt (line 5)) (1.16.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain->-r /content/LLM-WebToGraph/requirements.txt (line 2))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: neo4j\n",
            "  Building wheel for neo4j (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neo4j: filename=neo4j-5.19.0-py3-none-any.whl size=280741 sha256=cc5d05f56a96492940b5b113313db5733a2efb08d5f76cc8b046651e06506831\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/db/9b/2cfde1fa33145219c0322f299b604daf5aba2ed443a7ed5f07\n",
            "Successfully built neo4j\n",
            "Installing collected packages: watchdog, smmap, pyee, packaging, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, neo4j, mypy-extensions, jsonpointer, httpcore, backoff, typing-inspect, pydeck, playwright, nvidia-cusparse-cu12, nvidia-cudnn-cu12, marshmallow, jsonpatch, httpx, gitdb, openai, nvidia-cusolver-cu12, langsmith, gitpython, dataclasses-json, langchain-core, streamlit, langchain-text-splitters, langchain-community, bitsandbytes, accelerate, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed accelerate-0.28.0 backoff-2.2.1 bitsandbytes-0.43.0 dataclasses-json-0.6.4 gitdb-4.0.11 gitpython-3.1.43 httpcore-1.0.5 httpx-0.27.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.14 langchain-community-0.0.31 langchain-core-0.1.38 langchain-text-splitters-0.0.1 langsmith-0.1.38 marshmallow-3.21.1 mypy-extensions-1.0.0 neo4j-5.19.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 openai-1.16.1 orjson-3.10.0 packaging-23.2 playwright-1.42.0 pydeck-0.8.1b0 pyee-11.0.1 smmap-5.0.1 streamlit-1.32.2 typing-inspect-0.9.0 watchdog-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install uvicorn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTTOwC9bh4L7",
        "outputId": "a6ab0b70-7451-478c-dab0-ea64b2f72895"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/60.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (4.10.0)\n",
            "Installing collected packages: h11, uvicorn\n",
            "Successfully installed h11-0.14.0 uvicorn-0.29.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ulUhkMYiBRD",
        "outputId": "062f5b82-f137-422d-ee0a-38f2c0f84c0e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fastapi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2qS9gSyiGxy",
        "outputId": "a8fe5e47-b6ef-48cd-e569-e89077b7fdd4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.110.1-py3-none-any.whl (91 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/91.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.6.4)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/71.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.16.3)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.38.0,>=0.37.2->fastapi) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (1.2.0)\n",
            "Installing collected packages: starlette, fastapi\n",
            "Successfully installed fastapi-0.110.1 starlette-0.37.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tenacity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmtqrUYHivXF",
        "outputId": "2138f0e1-fd11-4178-fbce-5a39ed1e8127"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (8.2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import backoff\n",
        "import openai  # for OpenAI API calls\n",
        "from dotenv import load_dotenv\n",
        "from langchain.chains import create_extraction_chain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from tenacity import (\n",
        "    retry,\n",
        "    stop_after_attempt,\n",
        "    wait_random_exponential,\n",
        ")  # for exponential backoff\n",
        "\n",
        "from m1.src.app import utils\n",
        "from m1.src.components.base_component import BaseComponent\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "def get_schema():\n",
        "    \"\"\"\n",
        "    The get_schema function reads the schema.yml file and returns a dictionary of the schema.\n",
        "\n",
        "    :return: The schema\n",
        "    :doc-author: Trelent\n",
        "    \"\"\"\n",
        "    schema = utils.read_yaml_file('services/schema.yml')\n",
        "    return schema\n",
        "\n",
        "\n",
        "class Llm(BaseComponent):\n",
        "\n",
        "    def __init__(self, model: str):\n",
        "        super().__init__('Lllm')\n",
        "        self.model = model\n",
        "        # for huggingface hub models\n",
        "        # self.llm = HuggingFaceHub(repo_id='ValiantLabs/ShiningValiant', task='text-generation',\n",
        "        #                           huggingfacehub_api_token=os.getenv('HF_AUTH_TOKEN'),\n",
        "        #                           model_kwargs={\"temperature\": 0, \"max_length\": 64})\n",
        "        self.llm = ChatOpenAI(temperature=0, model_name=model, openai_api_key=os.getenv('OPENAI_API_KEY'))\n",
        "\n",
        "    @backoff.on_exception(backoff.expo, Exception)\n",
        "    @retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
        "    def run(self, input_text):\n",
        "        \"\"\"\n",
        "        The run function is the main entry point for your component.\n",
        "        It will be called with a string of text to process, and should return a dictionary of results.\n",
        "        The keys in this dictionary are the names of slots that you defined in your schema.\n",
        "\n",
        "        :param self: Represent the instance of the class\n",
        "        :param input_text: Pass the text that we want to extract entities from\n",
        "        :return: A dictionary with the following structure:\n",
        "        \"\"\"\n",
        "        schema = get_schema()\n",
        "        self.logger.info(f'schema: {schema}')\n",
        "        chain = create_extraction_chain(schema, self.llm)\n",
        "        llm_response = chain.run(input_text)\n",
        "        self.logger.info(f'llm_response: {llm_response}')\n",
        "        return llm_response"
      ],
      "metadata": {
        "id": "uJJzycy3ibe2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Union, List\n",
        "\n",
        "from langchain.document_loaders import AsyncHtmlLoader\n",
        "from langchain.document_transformers import BeautifulSoupTransformer\n",
        "from m1.src.app import utils\n",
        "from m1.src.app.llm import Llm\n",
        "from m1.src.components.base_component import BaseComponent\n",
        "from m1.src.datalayer.Neo4jDumper import Neo4jDumper\n",
        "\n",
        "\n",
        "class NameIdentityRetrievalForHtml(BaseComponent):\n",
        "    def __init__(self, model_name, data_path):\n",
        "\n",
        "        \"\"\"\n",
        "        The __init__ function is called when the class is instantiated.\n",
        "        It sets up the initial values of all attributes for an instance of a class.\n",
        "        The self parameter refers to the current instance of a class, and it's required by Python.\n",
        "\n",
        "        :param self: Represent the instance of the class\n",
        "        :param model_name: Specify the model name that we want to use for our predictions\n",
        "        :param data_path: Read the yaml file which contains the links to be scraped\n",
        "        :return: Nothing\n",
        "        \"\"\"\n",
        "        super().__init__('NameIdentityRetrievalForHtml')\n",
        "        self.sources = utils.read_yaml_file(data_path)\n",
        "        self.html_sources = self.sources.get('link', [])\n",
        "        # instantiating the openai llm model and neo4j connection\n",
        "        self.neo4j_instance = Neo4jDumper(config_path='app/config.yml')\n",
        "        self.open_ai_llm = Llm(model=model_name)\n",
        "\n",
        "    def run_async(self, **kwargs):\n",
        "\n",
        "        \"\"\"\n",
        "        The run_async function is used to run the pipeline asynchronously.\n",
        "            It takes in a list of html sources and extracts knowledge graph from them using openai api.\n",
        "            The extracted knowledge graph is then dumped into neo4j database.\n",
        "\n",
        "        :param self: Represent the instance of the object itself\n",
        "        :param **kwargs: Pass a variable number of keyword arguments to a function\n",
        "        :return: A list of all the knowledge graphs extracted from the html sources\n",
        "        \"\"\"\n",
        "        for link in self.html_sources:\n",
        "            loader =AsyncHtmlLoader(link)\n",
        "            html = loader.load()\n",
        "            # html = loader.load()\n",
        "            bs_transformer = BeautifulSoupTransformer()\n",
        "            docs_transformed = bs_transformer.transform_documents(html, tags_to_extract=[\"table\"])\n",
        "            self.logger.info(docs_transformed[0].page_content[0:500])\n",
        "\n",
        "            # setting up openai model and extracting knowledge graph\n",
        "            self.logger.info(f'loading model {self.open_ai_llm}')\n",
        "\n",
        "            # just sending last few lines of csv as the token limit is limited of openai api free version.\n",
        "            # model should  be changed to claude2 (Anthropic) or premium openai api key should be used.\n",
        "            # response = self.open_ai_llm.extract_and_store_graph(document=docs_transformed[0])\n",
        "            tokens_cap = len(docs_transformed[0].page_content) - 4\n",
        "            response = self.open_ai_llm.run(input_text=docs_transformed[0].page_content[tokens_cap:])\n",
        "            # instantiating neo4jBD and dumping the knowledge graph\n",
        "            self.neo4j_instance.run(data=response)\n",
        "            self.logger.info(f'knowledge graph populated successfully for data source: {link}')\n",
        "\n",
        "    def run(self, input: Union[str, List[float]]) -> str:\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "bakwFjLMmwnq"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "from langchain.graphs.graph_document import (\n",
        "    Node as BaseNode,\n",
        "    Relationship as BaseRelationship\n",
        ")\n",
        "from langchain.pydantic_v1 import Field, BaseModel\n",
        "\n",
        "\n",
        "class Property(BaseModel):\n",
        "    \"\"\"A single property consisting of key and value\"\"\"\n",
        "    key: str = Field(..., description=\"key\")\n",
        "    value: str = Field(..., description=\"value\")\n",
        "\n",
        "\n",
        "class Node(BaseNode):\n",
        "    properties: Optional[List[Property]] = Field(\n",
        "        None, description=\"List of node properties\")\n",
        "\n",
        "\n",
        "class Relationship(BaseRelationship):\n",
        "    properties: Optional[List[Property]] = Field(\n",
        "        None, description=\"List of relationship properties\"\n",
        "    )\n",
        "\n",
        "\n",
        "class KnowledgeGraph(BaseModel):\n",
        "    \"\"\"Generate a knowledge graph with entities and relationships.\"\"\"\n",
        "    nodes: List[Node] = Field(\n",
        "        ..., description=\"List of nodes in the knowledge graph\")\n",
        "    rels: List[Relationship] = Field(\n",
        "        ..., description=\"List of relationships in the knowledge graph\"\n",
        "    )\n",
        "\n",
        "\n",
        "def format_property_key(s: str) -> str:\n",
        "    words = s.split()\n",
        "    if not words:\n",
        "        return s\n",
        "    first_word = words[0].lower()\n",
        "    capitalized_words = [word.capitalize() for word in words[1:]]\n",
        "    return \"\".join([first_word] + capitalized_words)\n",
        "\n",
        "\n",
        "def props_to_dict(props) -> dict:\n",
        "    \"\"\"Convert properties to a dictionary.\"\"\"\n",
        "    properties = {}\n",
        "    if not props:\n",
        "        return properties\n",
        "    for p in props:\n",
        "        properties[format_property_key(p.key)] = p.value\n",
        "    return properties\n",
        "\n",
        "\n",
        "def map_to_base_node(node: Node) -> BaseNode:\n",
        "    \"\"\"Map the KnowledgeGraph Node to the base Node.\"\"\"\n",
        "    properties = props_to_dict(node.properties) if node.properties else {}\n",
        "    # Add name property for better Cypher statement generation\n",
        "    properties[\"name\"] = node.id.title()\n",
        "    return BaseNode(\n",
        "        id=node.id.title(), type=node.type.capitalize(), properties=properties\n",
        "    )\n",
        "\n",
        "\n",
        "def map_to_base_relationship(rel: Relationship) -> BaseRelationship:\n",
        "    \"\"\"Map the KnowledgeGraph Relationship to the base Relationship.\"\"\"\n",
        "    source = map_to_base_node(rel.source)\n",
        "    target = map_to_base_node(rel.target)\n",
        "    properties = props_to_dict(rel.properties) if rel.properties else {}\n",
        "    return BaseRelationship(\n",
        "        source=source, target=target, type=rel.type, properties=properties\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLR9vk8um6d6",
        "outputId": "031d3b68-c71b-43e0-9f36-8d40a748885f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/tokenize.py:527: RuntimeWarning: coroutine 'Server.serve' was never awaited\n",
            "  pseudomatch = _compile(PseudoToken).match(line, pos)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
            "ERROR:asyncio:Task was destroyed but it is pending!\n",
            "task: <Task pending name='Task-2' coro=<LifespanOn.main() running at /usr/local/lib/python3.10/dist-packages/uvicorn/lifespan/on.py:86> wait_for=<Future pending cb=[Task.__wakeup()]>>\n",
            "ERROR:    Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 741, in lifespan\n",
            "    await receive()\n",
            "GeneratorExit\n",
            "\n",
            "ERROR:asyncio:Task was destroyed but it is pending!\n",
            "task: <Task pending name='Task-4' coro=<LifespanOn.main() running at /usr/local/lib/python3.10/dist-packages/uvicorn/lifespan/on.py:86> wait_for=<Future pending cb=[Task.__wakeup()]>>\n",
            "ERROR:    Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 741, in lifespan\n",
            "    await receive()\n",
            "GeneratorExit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.graphs import Neo4jGraph\n",
        "from langchain.graphs.graph_document import GraphDocument\n",
        "from neo4j import GraphDatabase\n",
        "\n",
        "from m1.src.app import utils\n",
        "from m1.src.components.base_component import BaseComponent\n",
        "from m1.src.datalayer.KnowledgeGraph import map_to_base_node, map_to_base_relationship\n",
        "\n",
        "\n",
        "class Neo4jDumper(BaseComponent):\n",
        "    def __init__(self, config_path):\n",
        "        super().__init__('Neo4jDumper')\n",
        "        config = utils.read_yaml_file(config_path)\n",
        "        self.uri = config.get('neo4j').get('uri')\n",
        "        self.username = config.get('neo4j').get('username')\n",
        "        self.password = config.get('neo4j').get('password')\n",
        "        self.graph = Neo4jGraph(\n",
        "            url=self.uri, username=self.username, password=self.password\n",
        "        )\n",
        "\n",
        "    def dump_data(self, tx, data):\n",
        "        for key, value in data.items():\n",
        "            # Create a node for each key-value pair\n",
        "            tx.run(query=\"CREATE (n:Node {key: $key, value: $value})\", key=key, value=value)\n",
        "            self.logger.info(f\"Dumped data for {key}: {value} to neo4j\")\n",
        "\n",
        "    def run(self, data):\n",
        "        try:\n",
        "            with GraphDatabase.driver(self.uri, auth=(self.username, self.password)) as driver:\n",
        "                with driver.session() as session:\n",
        "                    self.dump_data(session, data)\n",
        "            self.logger.info(\"Neo4j database connected successfully. and data dumped successfully.\")\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error while connecting to neo4j: {str(e)}\")\n",
        "        finally:\n",
        "            session.close()\n",
        "\n",
        "    # New implementation using graph document\n",
        "    def run2(self, data, document):\n",
        "        try:\n",
        "            graph = Neo4jGraph(\n",
        "                url=self.uri, username=self.username, password=self.password\n",
        "            )\n",
        "            # Construct a graph document\n",
        "            graph_document = GraphDocument(\n",
        "                nodes=[map_to_base_node(node) for node in data.nodes],\n",
        "                relationships=[map_to_base_relationship(rel) for rel in data.rels],\n",
        "                source=document\n",
        "            )\n",
        "            # Store information into a graph\n",
        "            graph.add_graph_documents([graph_document])\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error while connecting to neo4j: {str(e)}\")\n"
      ],
      "metadata": {
        "id": "fDYBn0Gom845"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from m1.src.app import utils\n",
        "from m1.src.components.base_component import BaseComponent\n",
        "\n",
        "pre_defined_sources = ('link', 'csv')\n",
        "\n",
        "\n",
        "class DataPreprocessor(BaseComponent):\n",
        "    def __init__(self, datasource):\n",
        "        super().__init__('DataPreprocessor')\n",
        "        self.sources = utils.read_yaml_file(datasource)\n",
        "        self.csv_sources = self.sources.get('csv', [])\n",
        "        self.html_sources = self.sources.get('link', [])\n",
        "\n",
        "    def get_csv_sources(self):\n",
        "        return self.csv_sources\n",
        "\n",
        "    def get_html_sources(self):\n",
        "        return self.html_sources\n",
        "\n",
        "    def run(self, **kwargs):\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "yvNysadMnCnr"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import GraphCypherQAChain\n",
        "from m1.src.app.llm import Llm\n",
        "from m1.src.components.base_component import BaseComponent\n",
        "from m1.src.datalayer.Neo4jDumper import Neo4jDumper\n",
        "\n",
        "\n",
        "class CypherQa(BaseComponent):\n",
        "    def __init__(self, model_name):\n",
        "        super().__init__('cypher_qa')\n",
        "        # instantiating the openai llm model and neo4j connection\n",
        "        self.neo4j_instance = Neo4jDumper(config_path='app/config.yml')\n",
        "        self.open_ai_llm = Llm(model=model_name)\n",
        "        # schema = utils.read_yaml_file('services/schemaN.yml')\n",
        "        # graph_schema = construct_schema(schema,[],[])\n",
        "        print(self.neo4j_instance.graph.schema)\n",
        "        self.cypher_chain = GraphCypherQAChain.from_llm(\n",
        "            cypher_llm=self.open_ai_llm.llm,\n",
        "            qa_llm=self.open_ai_llm.llm,\n",
        "            graph=self.neo4j_instance.graph,\n",
        "            # validate_cypher=True,  # Validate relationship directions\n",
        "            verbose=True,\n",
        "        )\n",
        "\n",
        "    def run(self, text):\n",
        "        return self.cypher_chain.run(text)\n"
      ],
      "metadata": {
        "id": "wpvbgv4Pnm0t"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "sljwduewlEVh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "\n",
        "def read_yaml_file(file_path):\n",
        "    \"\"\"\n",
        "    Load a YAML file and return its contents as a Python dictionary.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the YAML file.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the YAML configuration.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, \"r\") as yaml_file:\n",
        "            config = yaml.safe_load(yaml_file)\n",
        "        return config\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Config file not found at {file_path}\")\n",
        "        return {}\n",
        "    except yaml.YAMLError as e:\n",
        "        print(f\"Error: Failed to load YAML from {file_path}. {e}\")\n",
        "        return {}\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "82EORn9unyBL"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import streamlit as st\n",
        "\n",
        "st.title(\"LLM-WebToGraph\")\n",
        "st.text(\n",
        "    'This project using langchain and OpenAI LLM to transform data from different sources (weblinks/csv) to knowledge graph and store then in neo4j DB.')\n",
        "st.write('Press submit to upload process the data and generate knowledge graph.')\n",
        "\n",
        "if st.button(\"process csv files and generate knowledge graph\"):\n",
        "    # Send user_input to FastAPI\n",
        "    fastapi_url = \"http://localhost:8000/generate_tags_from_csv\"\n",
        "    response = requests.get(fastapi_url)\n",
        "    if response.status_code == 200:\n",
        "        st.write(f\"{response.text}\")\n",
        "    else:\n",
        "        st.error(f\"Error: {response.status_code}\")\n",
        "\n",
        "if st.button(\"process html links and generate knowledge graph\"):\n",
        "    # Send user_input to FastAPI\n",
        "    fastapi_url = \"http://localhost:8000/generate_tags_from_html\"\n",
        "    response = requests.get(fastapi_url)\n",
        "    if response.status_code == 200:\n",
        "        st.write(f\"{response.text}\")\n",
        "    else:\n",
        "        st.error(f\"Error: {response.status_code}\")\n",
        "\n",
        "user_input = st.text_input(\"ask any question about data\")\n",
        "if st.button('submit'):\n",
        "    # Send user_input to FastAPI\n",
        "    fastapi_url = f\"http://localhost:8000/query_graph/{user_input}\"\n",
        "    response = requests.get(fastapi_url)\n",
        "    if response.status_code == 200:\n",
        "        st.write(f\"{response.text}\")\n",
        "    else:\n",
        "        st.error(f\"Error: {response.status_code}\")\n"
      ],
      "metadata": {
        "id": "eAaMeC9hn1oj"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import uvicorn\n",
        "from dotenv import load_dotenv\n",
        "from fastapi import FastAPI\n",
        "from fastapi.responses import HTMLResponse\n",
        "\n",
        "from m1.src.app import utils\n",
        "from m1.src.services.Identity_retrival_for_csv import NameIdentityRetrievalForCsv\n",
        "from m1.src.services.Identity_retrival_for_html import NameIdentityRetrievalForHtml\n",
        "from m1.src.services.cypher_qa import CypherQa\n",
        "\n",
        "app = FastAPI(\n",
        "    title=\"LLM-WebToGrap\",\n",
        "    description=\"\"\"This project using langchain and OpenAI LLM to transform data from different sources (web\n",
        "    links/csv) to knowledge graph and store then in neo4j DB.\"\"\",\n",
        "    version=\"0.1.0\",\n",
        ")\n",
        "\n",
        "\n",
        "@app.get(\"/query_graph/{question}\")\n",
        "def query_graph(question: str):\n",
        "\n",
        "    \"\"\"\n",
        "    The query_graph function takes a question as input and returns the answer to that question.\n",
        "    The function uses the CypherQa class from the cypher_qachain package, which is an implementation of\n",
        "    the QAChain algorithm for answering questions about graphs using GPT-3. The model used by this function\n",
        "    is gpt-3.5-turbo, which was trained on a dataset of ~100k questions and answers about graphs.\n",
        "\n",
        "    :param question: str: Pass the question to the function\n",
        "    :return: A htmlresponse object\n",
        "\n",
        "    \"\"\"\n",
        "    graph_cypher_qachain = CypherQa(model_name='gpt-3.5-turbo')\n",
        "    response = graph_cypher_qachain.run(question)\n",
        "    return HTMLResponse(content=response, status_code=200)\n",
        "\n",
        "\n",
        "@app.get(\"/generate_tags_from_html\")\n",
        "async def generate_tags():\n",
        "    \"\"\"\n",
        "    The generate_tags function is a ReST endpoint that will generate the tags for all the data sources.\n",
        "    This function is called by an external service, such as Jenkins or Travis CI, to ensure that the tags are up-to-date.\n",
        "    The function returns a 200 status code if successful and 500 otherwise.\n",
        "\n",
        "    :return: A htmlresponse object with the content as 'successfully generated the knowledge from the data sources!!!' and status_code as 200\n",
        "\n",
        "    \"\"\"\n",
        "    ner = NameIdentityRetrievalForHtml(model_name='gpt-3.5-turbo', data_path='datalayer/datasources.yml')\n",
        "    ner.run_async()  # asyncronous call since html pages can take time to load and scrape\n",
        "    return HTMLResponse(content='Successfully generated the knowledge from the data sources!!!', status_code=200)\n",
        "\n",
        "\n",
        "@app.get(\"/generate_tags_from_csv\")\n",
        "def generate_tags():\n",
        "    \"\"\"\n",
        "    The generate_tags function is a ReST endpoint that will generate the tags for each of the data sources.\n",
        "        It uses the NameIdentityRetrievalForCsv class to accomplish this task.\n",
        "        The model_name and data_path are passed as parameters to this function.\n",
        "\n",
        "    :return: A htmlresponse object with the status code 200\n",
        "    \"\"\"\n",
        "    ner = NameIdentityRetrievalForCsv(model_name='gpt-3.5-turbo', data_path='datalayer/datasources.yml')\n",
        "    ner.run()\n",
        "    return HTMLResponse(content='Successfully generated the knowledge from the data sources!!!', status_code=200)\n",
        "\n",
        "\n",
        "# health check route\n",
        "@app.get(\"/health\")\n",
        "def health_check():\n",
        "    return {\"status\": \"healthy\"}\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app_config = utils.read_yaml_file('/content/m1/src/app/config.yml')\n",
        "    load_dotenv()\n",
        "    uvicorn.run(app, port=app_config.get('port'), host=app_config.get('host'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_OxO5Hkjm7c",
        "outputId": "fe989373-776d-4d80-da35-338d1982d501"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [846]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo lsof -i -P -n | grep LISTEN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHXdkAfmr5ht",
        "outputId": "763a1999-0211-49ed-ff3a-b25b57b8e193"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "node        7 root   21u  IPv6  19703      0t0  TCP *:8080 (LISTEN)\n",
            "kernel_ma  22 root    3u  IPv4  18488      0t0  TCP 172.28.0.12:6000 (LISTEN)\n",
            "colab-fil  60 root    3u  IPv4  18735      0t0  TCP 127.0.0.1:3453 (LISTEN)\n",
            "jupyter-n 110 root    7u  IPv4  18882      0t0  TCP 172.28.0.12:9000 (LISTEN)\n",
            "python3   846 root   21u  IPv4  39352      0t0  TCP 127.0.0.1:37689 (LISTEN)\n",
            "python3   881 root    3u  IPv4  39821      0t0  TCP 127.0.0.1:46561 (LISTEN)\n",
            "python3   881 root    4u  IPv4  39822      0t0  TCP 127.0.0.1:38643 (LISTEN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!printenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7es3vIgocC6",
        "outputId": "4fd28362-7416-4f63-d260-61bd4ec49a58"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SHELL=/bin/bash\n",
            "NV_LIBCUBLAS_VERSION=12.2.5.6-1\n",
            "NVIDIA_VISIBLE_DEVICES=all\n",
            "COLAB_JUPYTER_TRANSPORT=ipc\n",
            "NV_NVML_DEV_VERSION=12.2.140-1\n",
            "NV_CUDNN_PACKAGE_NAME=libcudnn8\n",
            "CGROUP_MEMORY_EVENTS=/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events\n",
            "NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.19.3-1+cuda12.2\n",
            "NV_LIBNCCL_DEV_PACKAGE_VERSION=2.19.3-1\n",
            "VM_GCE_METADATA_HOST=169.254.169.253\n",
            "HOSTNAME=7ef427e43362\n",
            "LANGUAGE=en_US\n",
            "TBE_RUNTIME_ADDR=172.28.0.1:8011\n",
            "COLAB_TPU_1VM=\n",
            "GCE_METADATA_TIMEOUT=3\n",
            "NVIDIA_REQUIRE_CUDA=cuda>=12.2 brand=tesla,driver>=470,driver<471 brand=unknown,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=geforce,driver>=470,driver<471 brand=geforcertx,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=titan,driver>=470,driver<471 brand=titanrtx,driver>=470,driver<471 brand=tesla,driver>=525,driver<526 brand=unknown,driver>=525,driver<526 brand=nvidia,driver>=525,driver<526 brand=nvidiartx,driver>=525,driver<526 brand=geforce,driver>=525,driver<526 brand=geforcertx,driver>=525,driver<526 brand=quadro,driver>=525,driver<526 brand=quadrortx,driver>=525,driver<526 brand=titan,driver>=525,driver<526 brand=titanrtx,driver>=525,driver<526\n",
            "NV_LIBCUBLAS_DEV_PACKAGE=libcublas-dev-12-2=12.2.5.6-1\n",
            "NV_NVTX_VERSION=12.2.140-1\n",
            "COLAB_JUPYTER_IP=172.28.0.12\n",
            "NV_CUDA_CUDART_DEV_VERSION=12.2.140-1\n",
            "NV_LIBCUSPARSE_VERSION=12.1.2.141-1\n",
            "COLAB_LANGUAGE_SERVER_PROXY_ROOT_URL=http://172.28.0.1:8013/\n",
            "NV_LIBNPP_VERSION=12.2.1.4-1\n",
            "NCCL_VERSION=2.19.3-1\n",
            "KMP_LISTEN_PORT=6000\n",
            "TF_FORCE_GPU_ALLOW_GROWTH=true\n",
            "ENV=/root/.bashrc\n",
            "PWD=/content\n",
            "TBE_EPHEM_CREDS_ADDR=172.28.0.1:8009\n",
            "COLAB_LANGUAGE_SERVER_PROXY_REQUEST_TIMEOUT=30s\n",
            "TBE_CREDS_ADDR=172.28.0.1:8008\n",
            "NV_CUDNN_PACKAGE=libcudnn8=8.9.6.50-1+cuda12.2\n",
            "NVIDIA_DRIVER_CAPABILITIES=compute,utility\n",
            "COLAB_JUPYTER_TOKEN=\n",
            "LAST_FORCED_REBUILD=20240321\n",
            "NV_NVPROF_DEV_PACKAGE=cuda-nvprof-12-2=12.2.142-1\n",
            "NV_LIBNPP_PACKAGE=libnpp-12-2=12.2.1.4-1\n",
            "NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "TCLLIBPATH=/usr/share/tcltk/tcllib1.20\n",
            "NV_LIBCUBLAS_DEV_VERSION=12.2.5.6-1\n",
            "COLAB_KERNEL_MANAGER_PROXY_HOST=172.28.0.12\n",
            "NVIDIA_PRODUCT_NAME=CUDA\n",
            "NV_LIBCUBLAS_DEV_PACKAGE_NAME=libcublas-dev-12-2\n",
            "USE_AUTH_EPHEM=1\n",
            "NV_CUDA_CUDART_VERSION=12.2.140-1\n",
            "COLAB_WARMUP_DEFAULTS=1\n",
            "HOME=/root\n",
            "LANG=en_US.UTF-8\n",
            "COLUMNS=100\n",
            "CUDA_VERSION=12.2.2\n",
            "CLOUDSDK_CONFIG=/content/.config\n",
            "NV_LIBCUBLAS_PACKAGE=libcublas-12-2=12.2.5.6-1\n",
            "NV_CUDA_NSIGHT_COMPUTE_DEV_PACKAGE=cuda-nsight-compute-12-2=12.2.2-1\n",
            "COLAB_RELEASE_TAG=release-colab_20240329-060116_RC00\n",
            "PYDEVD_USE_FRAME_EVAL=NO\n",
            "KMP_TARGET_PORT=9000\n",
            "CLICOLOR=1\n",
            "KMP_EXTRA_ARGS=--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https://colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-3upi6eq3z59vh --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true\n",
            "NV_LIBNPP_DEV_PACKAGE=libnpp-dev-12-2=12.2.1.4-1\n",
            "COLAB_LANGUAGE_SERVER_PROXY_LSP_DIRS=/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages\n",
            "NV_LIBCUBLAS_PACKAGE_NAME=libcublas-12-2\n",
            "COLAB_KERNEL_MANAGER_PROXY_PORT=6000\n",
            "CLOUDSDK_PYTHON=python3\n",
            "NV_LIBNPP_DEV_VERSION=12.2.1.4-1\n",
            "ENABLE_DIRECTORYPREFETCHER=1\n",
            "NO_GCE_CHECK=False\n",
            "JPY_PARENT_PID=110\n",
            "PYTHONPATH=/env/python\n",
            "TERM=xterm-color\n",
            "NV_LIBCUSPARSE_DEV_VERSION=12.1.2.141-1\n",
            "GIT_PAGER=cat\n",
            "LIBRARY_PATH=/usr/local/cuda/lib64/stubs\n",
            "NV_CUDNN_VERSION=8.9.6.50\n",
            "SHLVL=0\n",
            "PAGER=cat\n",
            "COLAB_LANGUAGE_SERVER_PROXY=/usr/colab/bin/language_service\n",
            "NV_CUDA_LIB_VERSION=12.2.2-1\n",
            "NVARCH=x86_64\n",
            "NV_CUDNN_PACKAGE_DEV=libcudnn8-dev=8.9.6.50-1+cuda12.2\n",
            "NV_CUDA_COMPAT_PACKAGE=cuda-compat-12-2\n",
            "MPLBACKEND=Agg\n",
            "NV_LIBNCCL_PACKAGE=libnccl2=2.19.3-1+cuda12.2\n",
            "LD_LIBRARY_PATH=/usr/lib64-nvidia\n",
            "COLAB_GPU=1\n",
            "GCS_READ_CACHE_BLOCK_SIZE_MB=16\n",
            "NV_CUDA_NSIGHT_COMPUTE_VERSION=12.2.2-1\n",
            "NV_NVPROF_VERSION=12.2.142-1\n",
            "LC_ALL=en_US.UTF-8\n",
            "COLAB_FILE_HANDLER_ADDR=localhost:3453\n",
            "PATH=/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin\n",
            "NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "COLAB_DEBUG_ADAPTER_MUX_PATH=/usr/local/bin/dap_multiplexer\n",
            "NV_LIBNCCL_PACKAGE_VERSION=2.19.3-1\n",
            "PYTHONWARNINGS=ignore:::pip._internal.cli.base_command\n",
            "DEBIAN_FRONTEND=noninteractive\n",
            "COLAB_BACKEND_VERSION=next\n",
            "OLDPWD=/\n",
            "_=/usr/bin/printenv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uvicorn\n",
        "from dotenv import load_dotenv\n",
        "from fastapi import FastAPI\n",
        "from fastapi.responses import HTMLResponse\n",
        "\n",
        "from m1.src.app import utils\n",
        "from m1.src.services.Identity_retrival_for_csv import NameIdentityRetrievalForCsv\n",
        "from m1.src.services.Identity_retrival_for_html import NameIdentityRetrievalForHtml\n",
        "from m1.src.services.cypher_qa import CypherQa\n",
        "\n",
        "app = FastAPI(\n",
        "    title=\"LLM-WebToGrap\",\n",
        "    description=\"\"\"This project using langchain and OpenAI LLM to transform data from different sources (web\n",
        "    links/csv) to knowledge graph and store then in neo4j DB.\"\"\",\n",
        "    version=\"0.1.0\",\n",
        ")\n",
        "\n",
        "\n",
        "@app.get(\"/query_graph/{question}\")\n",
        "def query_graph(question: str):\n",
        "\n",
        "    \"\"\"\n",
        "    The query_graph function takes a question as input and returns the answer to that question.\n",
        "    The function uses the CypherQa class from the cypher_qachain package, which is an implementation of\n",
        "    the QAChain algorithm for answering questions about graphs using GPT-3. The model used by this function\n",
        "    is gpt-3.5-turbo, which was trained on a dataset of ~100k questions and answers about graphs.\n",
        "\n",
        "    :param question: str: Pass the question to the function\n",
        "    :return: A htmlresponse object\n",
        "\n",
        "    \"\"\"\n",
        "    graph_cypher_qachain = CypherQa(model_name='gpt-3.5-turbo')\n",
        "    response = graph_cypher_qachain.run(question)\n",
        "    return HTMLResponse(content=response, status_code=200)\n",
        "\n",
        "\n",
        "@app.get(\"/generate_tags_from_html\")\n",
        "async def generate_tags():\n",
        "    \"\"\"\n",
        "    The generate_tags function is a ReST endpoint that will generate the tags for all the data sources.\n",
        "    This function is called by an external service, such as Jenkins or Travis CI, to ensure that the tags are up-to-date.\n",
        "    The function returns a 200 status code if successful and 500 otherwise.\n",
        "\n",
        "    :return: A htmlresponse object with the content as 'successfully generated the knowledge from the data sources!!!' and status_code as 200\n",
        "\n",
        "    \"\"\"\n",
        "    ner = NameIdentityRetrievalForHtml(model_name='gpt-3.5-turbo', data_path='datalayer/datasources.yml')\n",
        "    ner.run_async()  # asyncronous call since html pages can take time to load and scrape\n",
        "    return HTMLResponse(content='Successfully generated the knowledge from the data sources!!!', status_code=200)\n",
        "\n",
        "\n",
        "@app.get(\"/generate_tags_from_csv\")\n",
        "def generate_tags():\n",
        "    \"\"\"\n",
        "    The generate_tags function is a ReST endpoint that will generate the tags for each of the data sources.\n",
        "        It uses the NameIdentityRetrievalForCsv class to accomplish this task.\n",
        "        The model_name and data_path are passed as parameters to this function.\n",
        "\n",
        "    :return: A htmlresponse object with the status code 200\n",
        "    \"\"\"\n",
        "    ner = NameIdentityRetrievalForCsv(model_name='gpt-3.5-turbo', data_path='datalayer/datasources.yml')\n",
        "    ner.run()\n",
        "    return HTMLResponse(content='Successfully generated the knowledge from the data sources!!!', status_code=200)\n",
        "\n",
        "\n",
        "# health check route\n",
        "@app.get(\"/health\")\n",
        "def health_check():\n",
        "    return {\"status\": \"healthy\"}\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app_config = utils.read_yaml_file('app/config.yml')\n",
        "    load_dotenv()\n",
        "    uvicorn.run(app, port=app_config.get('port'), host=app_config.get('host'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "EST161i8hzdq",
        "outputId": "86625beb-dd06-4a3f-9304-a4bda57f10ac"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Config file not found at app/config.yml\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "asyncio.run() cannot be called from a running event loop",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-7338a5c76cd2>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mapp_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_yaml_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'app/config.yml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mload_dotenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0muvicorn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapp_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'port'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapp_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'host'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/uvicorn/main.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0mMultiprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muds\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pragma: py-win32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, sockets)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msockets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msockets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \"\"\"\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m     34\u001b[0m             \"asyncio.run() cannot be called from a running event loop\")\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "FS6FBTan2x9R"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LcXVfclP2saL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@backoff.on_exception(backoff.expo, openai.error.OpenAIError)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "d-btXJSR2kao",
        "outputId": "eda7b9f4-f6f6-4ba0-a388-dfaf8bcb7461"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-19-fd2a75076f53>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-fd2a75076f53>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    @backoff.on_exception(backoff.expo, openai.error.OpenAIError)\u001b[0m\n\u001b[0m                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install backoff retry"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPsApPGfkcvx",
        "outputId": "87f53fd5-d3db-4c21-d6f6-87971ce21176"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting backoff\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting retry\n",
            "  Downloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\n",
            "Requirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.10/dist-packages (from retry) (4.4.2)\n",
            "Collecting py<2.0.0,>=1.4.26 (from retry)\n",
            "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: py, backoff, retry\n",
            "Successfully installed backoff-2.2.1 py-1.11.0 retry-0.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pu5l8tdjqes",
        "outputId": "cd08722e-4fb8-412f-e5d8-3e933a08626d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.16.0-py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.9/266.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: httpcore, httpx, openai\n",
            "Successfully installed httpcore-1.0.5 httpx-0.27.0 openai-1.16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install backoff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umdDybt1jgyM",
        "outputId": "21866f59-5556-4c08-e9f6-340002748309"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (2.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3QwqI9jiybF",
        "outputId": "01955b0f-6b00-4a24-e226-08f0ea46d519"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.14-py3-none-any.whl (812 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.8/812.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.30 (from langchain)\n",
            "  Downloading langchain_community-0.0.31-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.37 (from langchain)\n",
            "  Downloading langchain_core-0.1.38-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.2/279.2 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.38-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.37->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.14 langchain-community-0.0.31 langchain-core-0.1.38 langchain-text-splitters-0.0.1 langsmith-0.1.38 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.0 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ]
    }
  ]
}